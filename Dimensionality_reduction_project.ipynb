{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNcJxOmxz/RbiGfTXK361Bx",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/monika123-S/Dimension-Reduction-Using-K-Means-for-Activity-Recognition/blob/main/Dimensionality_reduction_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zH8T2YPtD6uM"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import zipfile\n",
        "import io\n",
        "import pandas as pd\n",
        "from sklearn.cluster import KMeans\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Function to download and load dataset\n",
        "def load_data():\n",
        "    page_url = 'https://archive.ics.uci.edu/dataset/240/human+activity+recognition+using+smartphones'\n",
        "    page_response = requests.get(page_url)\n",
        "    if page_response.status_code == 200:\n",
        "        soup = BeautifulSoup(page_response.content, 'html.parser')\n",
        "        download_link = soup.select_one('a[href$=\".zip\"]')['href']\n",
        "        full_download_url = 'https://archive.ics.uci.edu' + download_link\n",
        "        response = requests.get(full_download_url)\n",
        "        if response.status_code == 200:\n",
        "            with zipfile.ZipFile(io.BytesIO(response.content)) as outer_zip:\n",
        "                inner_zip_name = 'UCI HAR Dataset.zip'\n",
        "                with outer_zip.open(inner_zip_name) as inner_zip_file:\n",
        "                    with zipfile.ZipFile(io.BytesIO(inner_zip_file.read())) as inner_zip:\n",
        "                        with inner_zip.open('UCI HAR Dataset/train/X_train.txt') as myfile:\n",
        "                            df = pd.read_csv(myfile, delim_whitespace=True, header=None)\n",
        "                        with inner_zip.open('UCI HAR Dataset/train/y_train.txt') as myfile_y:\n",
        "                            y = pd.read_csv(myfile_y, delim_whitespace=True, header=None)\n",
        "    else:\n",
        "        raise Exception(\"Failed to download or parse the dataset.\")\n",
        "    return df, y"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.cluster import KMeans\n",
        "import numpy as np\n",
        "import time\n",
        "\n",
        "# Load dataset\n",
        "df, y = load_data()\n",
        "\n",
        "#TASK 1 - DO EDA and understand a little about the data.\n",
        "#Only important thing is to know that it has a lot of features that don't make sense, just a\n",
        "#bunch of readings from sensors.\n",
        "#We think many of these features are redundant or irrelevant, and we want to find good features.\n",
        "\n",
        "# Display first few rows of the dataset\n",
        "\n",
        "print(df.head())\n",
        "\n",
        "# Summary statistics\n",
        "print(df.describe())\n",
        "\n",
        "# Check for missing values\n",
        "print(df.isnull().sum())\n",
        "\n",
        "# Data type information\n",
        "print(df.info())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-biRK7RPEHVh",
        "outputId": "c2ded9cc-e0b5-488c-f290-0ae2cb617b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-836ccc4d8ebc>:30: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  df = pd.read_csv(myfile, delim_whitespace=True, header=None)\n",
            "<ipython-input-3-836ccc4d8ebc>:32: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  y = pd.read_csv(myfile_y, delim_whitespace=True, header=None)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        0         1         2         3         4         5         6    \\\n",
            "0  0.288585 -0.020294 -0.132905 -0.995279 -0.983111 -0.913526 -0.995112   \n",
            "1  0.278419 -0.016411 -0.123520 -0.998245 -0.975300 -0.960322 -0.998807   \n",
            "2  0.279653 -0.019467 -0.113462 -0.995380 -0.967187 -0.978944 -0.996520   \n",
            "3  0.279174 -0.026201 -0.123283 -0.996091 -0.983403 -0.990675 -0.997099   \n",
            "4  0.276629 -0.016570 -0.115362 -0.998139 -0.980817 -0.990482 -0.998321   \n",
            "\n",
            "        7         8         9    ...       551       552       553       554  \\\n",
            "0 -0.983185 -0.923527 -0.934724  ... -0.074323 -0.298676 -0.710304 -0.112754   \n",
            "1 -0.974914 -0.957686 -0.943068  ...  0.158075 -0.595051 -0.861499  0.053477   \n",
            "2 -0.963668 -0.977469 -0.938692  ...  0.414503 -0.390748 -0.760104 -0.118559   \n",
            "3 -0.982750 -0.989302 -0.938692  ...  0.404573 -0.117290 -0.482845 -0.036788   \n",
            "4 -0.979672 -0.990441 -0.942469  ...  0.087753 -0.351471 -0.699205  0.123320   \n",
            "\n",
            "        555       556       557       558       559       560  \n",
            "0  0.030400 -0.464761 -0.018446 -0.841247  0.179941 -0.058627  \n",
            "1 -0.007435 -0.732626  0.703511 -0.844788  0.180289 -0.054317  \n",
            "2  0.177899  0.100699  0.808529 -0.848933  0.180637 -0.049118  \n",
            "3 -0.012892  0.640011 -0.485366 -0.848649  0.181935 -0.047663  \n",
            "4  0.122542  0.693578 -0.615971 -0.847865  0.185151 -0.043892  \n",
            "\n",
            "[5 rows x 561 columns]\n",
            "               0            1            2            3            4    \\\n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
            "mean      0.274488    -0.017695    -0.109141    -0.605438    -0.510938   \n",
            "std       0.070261     0.040811     0.056635     0.448734     0.502645   \n",
            "min      -1.000000    -1.000000    -1.000000    -1.000000    -0.999873   \n",
            "25%       0.262975    -0.024863    -0.120993    -0.992754    -0.978129   \n",
            "50%       0.277193    -0.017219    -0.108676    -0.946196    -0.851897   \n",
            "75%       0.288461    -0.010783    -0.097794    -0.242813    -0.034231   \n",
            "max       1.000000     1.000000     1.000000     1.000000     0.916238   \n",
            "\n",
            "               5            6            7            8            9    ...  \\\n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000  ...   \n",
            "mean     -0.604754    -0.630512    -0.526907    -0.606150    -0.468604  ...   \n",
            "std       0.418687     0.424073     0.485942     0.414122     0.544547  ...   \n",
            "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  ...   \n",
            "25%      -0.980233    -0.993591    -0.978162    -0.980251    -0.936219  ...   \n",
            "50%      -0.859365    -0.950709    -0.857328    -0.857143    -0.881637  ...   \n",
            "75%      -0.262415    -0.292680    -0.066701    -0.265671    -0.017129  ...   \n",
            "max       1.000000     1.000000     0.967664     1.000000     1.000000  ...   \n",
            "\n",
            "               551          552          553          554          555  \\\n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000   \n",
            "mean      0.125293    -0.307009    -0.625294     0.008684     0.002186   \n",
            "std       0.250994     0.321011     0.307584     0.336787     0.448306   \n",
            "min      -1.000000    -0.995357    -0.999765    -0.976580    -1.000000   \n",
            "25%      -0.023692    -0.542602    -0.845573    -0.121527    -0.289549   \n",
            "50%       0.134000    -0.343685    -0.711692     0.009509     0.008943   \n",
            "75%       0.289096    -0.126979    -0.503878     0.150865     0.292861   \n",
            "max       0.946700     0.989538     0.956845     1.000000     1.000000   \n",
            "\n",
            "               556          557          558          559          560  \n",
            "count  7352.000000  7352.000000  7352.000000  7352.000000  7352.000000  \n",
            "mean      0.008726    -0.005981    -0.489547     0.058593    -0.056515  \n",
            "std       0.608303     0.477975     0.511807     0.297480     0.279122  \n",
            "min      -1.000000    -1.000000    -1.000000    -1.000000    -1.000000  \n",
            "25%      -0.482273    -0.376341    -0.812065    -0.017885    -0.143414  \n",
            "50%       0.008735    -0.000368    -0.709417     0.182071     0.003181  \n",
            "75%       0.506187     0.359368    -0.509079     0.248353     0.107659  \n",
            "max       0.998702     0.996078     1.000000     0.478157     1.000000  \n",
            "\n",
            "[8 rows x 561 columns]\n",
            "0      0\n",
            "1      0\n",
            "2      0\n",
            "3      0\n",
            "4      0\n",
            "      ..\n",
            "556    0\n",
            "557    0\n",
            "558    0\n",
            "559    0\n",
            "560    0\n",
            "Length: 561, dtype: int64\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 7352 entries, 0 to 7351\n",
            "Columns: 561 entries, 0 to 560\n",
            "dtypes: float64(561)\n",
            "memory usage: 31.5 MB\n",
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 2: Encode class labels\n",
        "# YOUR CODE HERE: Use LabelEncoder to encode class labels\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "encoded_y =label_encoder.fit_transform(y.values.ravel())"
      ],
      "metadata": {
        "id": "wth4sjWeEPJe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Task 3: Scale the features using StandardScaler\n",
        "# YOUR CODE HERE: Apply StandardScaler to df\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_scaled =scaler.fit_transform(df) # YOUR CODE HERE"
      ],
      "metadata": {
        "id": "vVLLweUVJV8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(df_scaled, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "a2a5M-H4K3qZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UXx9ARyjdaSs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "import time\n",
        "\n",
        "start_time=time.time()\n",
        "# 1. Create a pipeline using Gaussian Naive Bayes\n",
        "pipeline = Pipeline([('classifier', GaussianNB())])\n",
        "pipeline.fit(X_train, y_train.values.ravel())\n",
        "y_pred = pipeline.predict(X_test)\n",
        "end_time=time.time()\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1JDJQ8YeEiE",
        "outputId": "48b2a444-404c-4d82-dcdb-3427e83521d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken: 0.05854058265686035 seconds\n",
            "Accuracy: 0.7314751869476547\n"
          ]
        }
      ]
    },
    {
      "source": [
        "'''# TASK 7 - K-Means for dimensionality reduction\n",
        "n_clusters = 50  # Choose an appropriate number of clusters\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42)\n",
        "kmeans.fit(df_scaled.T)  # Transpose to treat features as data points\n",
        "selected_features_indices = []\n",
        "for i in range(n_clusters):\n",
        "    cluster_indices = np.where(kmeans.labels_ == i)[0]\n",
        "    selected_features_indices.append(cluster_indices[np.argmax(np.var(df_scaled[:, cluster_indices], axis=0))])\n",
        "selected_features = df.iloc[:, selected_features_indices]\n",
        "print(selected_features.head())'''"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qCAY9hMkA9A",
        "outputId": "fe235e11-3d2a-4a24-9ed8-14e17719cfae"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "        210       10        37        88        23        453       298  62   \\\n",
            "0 -0.022897 -0.567378  0.376314 -0.992818 -0.679338  0.547151 -0.220547 -1.0   \n",
            "1 -0.109366 -0.557851 -0.013429 -0.991277 -0.500930 -0.068178 -0.049709 -1.0   \n",
            "2 -0.074212 -0.557851 -0.124698 -0.987238 -0.485821 -0.110720  0.163063 -1.0   \n",
            "3  0.046396 -0.576159 -0.305693 -0.991483 -0.850930 -0.049728 -0.460915 -1.0   \n",
            "4 -0.277657 -0.569174 -0.155804 -0.990686 -0.559477 -0.162230 -0.180383 -1.0   \n",
            "\n",
            "        44        9    ...       337       78        161       379       156  \\\n",
            "0 -0.981708 -0.934724  ... -0.995146  0.439027 -0.055517 -0.507345 -0.331831   \n",
            "1 -0.989447 -0.943068  ... -0.998754 -0.865711 -0.044819 -0.655535 -0.149429   \n",
            "2 -0.992866 -0.938692  ... -0.999912  0.337936 -0.042410 -0.803407  0.184349   \n",
            "3 -0.981393 -0.938692  ... -0.999984 -0.968821 -0.036333 -0.577038  0.202092   \n",
            "4 -0.988098 -0.942469  ... -0.999436 -0.184840 -0.037633 -0.764369  0.473251   \n",
            "\n",
            "        75        81        30        120       188  \n",
            "0 -0.995668  0.005001 -0.224848 -0.006101 -0.039007  \n",
            "1 -0.834184  0.005771 -0.090963 -0.016112  0.041522  \n",
            "2 -0.723299  0.003104 -0.074507 -0.031698  0.089630  \n",
            "3 -0.387120  0.020058 -0.155320 -0.043410  0.316120  \n",
            "4 -0.241012  0.019122 -0.272505 -0.033960  0.200258  \n",
            "\n",
            "[5 rows x 50 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# SOLUTION -  K-Means for dimensionality reduction\n",
        "n_clusters = 50\n",
        "kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
        "kmeans.fit(df_scaled.T)  # Transpose to treat features as data points\n",
        "selected_features_indices = [np.random.choice(np.where(kmeans.labels_ == i)[0]) for i in range(n_clusters)]\n",
        "selected_features = df_scaled[:, selected_features_indices]\n",
        "print(selected_features)"
      ],
      "metadata": {
        "id": "HkqNKOcjkPzC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e066339f-743f-417c-d793-8165c9a894dd"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.57602421 -0.94666714 -0.7826638  ... -0.71840922  2.38058271\n",
            "   0.05426879]\n",
            " [ 1.100926   -1.14021606 -0.78177854 ...  0.24525519  1.24214562\n",
            "  -0.28975396]\n",
            " [ 0.51449745 -1.2108155  -0.78026501 ... -0.67367648  1.66521941\n",
            "   0.19924571]\n",
            " ...\n",
            " [-1.87078992  1.06645255  1.02663371 ...  0.4560065   0.12600117\n",
            "  -0.13816968]\n",
            " [-2.53817908  0.81598078  0.9767199  ...  0.23656391  0.4244078\n",
            "  -1.17094764]\n",
            " [-1.82848539  0.84970303  1.15550879 ...  0.15363336 -0.43604787\n",
            "  -1.00669305]]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "import time"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "mzjd5830uGjx"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "source": [
        "X_train_selected, X_test_selected, y_train, y_test = train_test_split(\n",
        "    selected_features, encoded_y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "ozITllVkuIm4"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "source": [
        "start_time = time.time()\n",
        "gnb_classifier = GaussianNB()\n",
        "gnb_classifier.fit(X_train_selected, y_train)\n",
        "end_time = time.time()\n",
        "print(f\"Time taken: {end_time - start_time} seconds\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r3N0ECtvuK4z",
        "outputId": "43b3d105-4414-49a4-e8fa-cc4e27aee6f7"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time taken: 0.013953924179077148 seconds\n"
          ]
        }
      ]
    },
    {
      "source": [
        "y_pred_gnb = gnb_classifier.predict(X_test_selected)\n",
        "accuracy_gnb = accuracy_score(y_test, y_pred_gnb)\n",
        "print(f\"Accuracy of Gaussian Naive Bayes: {accuracy_gnb}\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j123eDryuMvf",
        "outputId": "b72a2a85-3262-42b5-e453-aa9667c83890"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of Gaussian Naive Bayes: 0.8218898708361658\n"
          ]
        }
      ]
    }
  ]
}